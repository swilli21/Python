{"cells": [{"metadata": {}, "cell_type": "code", "source": "!mamba install bs4==4.10.0 -y\n!pip install lxml==4.6.4\n!mamba install html5lib==1.1 -y\n# !pip install requests==2.26.0", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "/usr/bin/sh: mamba: command not found\nCollecting lxml==4.6.4\n  Downloading lxml-4.6.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.9 MB 15.4 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: lxml\n  Attempting uninstall: lxml\n    Found existing installation: lxml 4.7.1\n    Uninstalling lxml-4.7.1:\n      Successfully uninstalled lxml-4.7.1\nSuccessfully installed lxml-4.6.4\n/usr/bin/sh: mamba: command not found\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from bs4 import BeautifulSoup # this module helps in web scrapping.\nimport requests  # this module helps us to download a web page", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%%html\n<!DOCTYPE html>\n<html>\n<head>\n<title>Page Title</title>\n</head>\n<body>\n<h3><b id='boldest'>Lebron James</b></h3>\n<p> Salary: $ 92,000,000 </p>\n<h3> Stephen Curry</h3>\n<p> Salary: $85,000, 000 </p>\n<h3> Kevin Durant </h3>\n<p> Salary: $73,200, 000</p>\n</body>\n</html>", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<!DOCTYPE html>\n<html>\n<head>\n<title>Page Title</title>\n</head>\n<body>\n<h3><b id='boldest'>Lebron James</b></h3>\n<p> Salary: $ 92,000,000 </p>\n<h3> Stephen Curry</h3>\n<p> Salary: $85,000, 000 </p>\n<h3> Kevin Durant </h3>\n<p> Salary: $73,200, 000</p>\n</body>\n</html>\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "html=\"<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>\"", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "soup = BeautifulSoup(html, \"html.parser\")", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Display the HTML in the nested structure\nprint(soup.prettify()) ", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "<!DOCTYPE html>\n<html>\n <head>\n  <title>\n   Page Title\n  </title>\n </head>\n <body>\n  <h3>\n   <b id=\"boldest\">\n    Lebron James\n   </b>\n  </h3>\n  <p>\n   Salary: $ 92,000,000\n  </p>\n  <h3>\n   Stephen Curry\n  </h3>\n  <p>\n   Salary: $85,000, 000\n  </p>\n  <h3>\n   Kevin Durant\n  </h3>\n  <p>\n   Salary: $73,200, 000\n  </p>\n </body>\n</html>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "tag_object=soup.title\nprint(\"tag object:\",tag_object)", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "tag object: <title>Page Title</title>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Tag type\nprint(\"tag object type:\",type(tag_object)) ", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "tag object type: <class 'bs4.element.Tag'>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#View the first element with the tag name\ntag_object=soup.h3\ntag_object", "execution_count": 9, "outputs": [{"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "<h3><b id=\"boldest\">Lebron James</b></h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "tag_child =tag_object.b\ntag_child", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "<b id=\"boldest\">Lebron James</b>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Access the parent\nparent_tag=tag_child.parent\nparent_tag", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "<h3><b id=\"boldest\">Lebron James</b></h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "tag_object", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "<h3><b id=\"boldest\">Lebron James</b></h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# tag_object parent is the body element\ntag_object.parent", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "<body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#tag_object sibling is the paragraph element\nsibling_1=tag_object.next_sibling\nsibling_1", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "<p> Salary: $ 92,000,000 </p>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Sibling_2 is the header element which is also a sibling of both sibling_1 and tag_object\nsibling_2=sibling_1.next_sibling\nsibling_2", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "<h3> Stephen Curry</h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Using the object sibling_2 and the property next_sibling to find the salary of Stephen Curry\nsibling_3 = sibling_2.next_sibling\nsibling_3", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "<p> Salary: $85,000, 000 </p>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#The tag id=\"boldest\", access a tag\u2019s attributes by treating the tag like a dictionary\ntag_child.attrs", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "{'id': 'boldest'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# obtain the content if the attribute of the tag using the Python get()\ntag_child.get('id')", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "'boldest'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Extracting the first string of the Tag object tag_child\ntag_string=tag_child.string\ntag_string", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "'Lebron James'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "type(tag_string)", "execution_count": 22, "outputs": [{"output_type": "execute_result", "execution_count": 22, "data": {"text/plain": "bs4.element.NavigableString"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "unicode_string = str(tag_string)\nunicode_string", "execution_count": 23, "outputs": [{"output_type": "execute_result", "execution_count": 23, "data": {"text/plain": "'Lebron James'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "%%html\n<table>\n  <tr>\n    <td id='flight' >Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n   </tr>\n  <tr> \n    <td>1</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n    <td>80 kg</td>\n  </tr>\n</table>", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n  <tr>\n    <td id='flight' >Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n   </tr>\n  <tr> \n    <td>1</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n    <td>80 kg</td>\n  </tr>\n</table>\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Store it as a string in the variable table:\ntable=\"<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>\"", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "table_bs = BeautifulSoup(table, \"html.parser\")", "execution_count": 26, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#name='tr' parameter to a tag name, the method will extract all the tags with that name and its children\ntable_rows=table_bs.find_all('tr')\ntable_rows", "execution_count": 27, "outputs": [{"output_type": "execute_result", "execution_count": 27, "data": {"text/plain": "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>,\n <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Result is a Python Iterable just like a list, each element is a tag object\nfirst_row =table_rows[0]\nfirst_row", "execution_count": 28, "outputs": [{"output_type": "execute_result", "execution_count": 28, "data": {"text/plain": "<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "print(type(first_row))", "execution_count": 29, "outputs": [{"output_type": "stream", "text": "<class 'bs4.element.Tag'>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Obtain the child (td)\nfirst_row.td", "execution_count": 30, "outputs": [{"output_type": "execute_result", "execution_count": 30, "data": {"text/plain": "<td id=\"flight\">Flight No</td>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#iterate through the list, each element corresponds to a row in the table\nfor i,row in enumerate(table_rows):\n    print(\"row\",i,\"is\",row)", "execution_count": 31, "outputs": [{"output_type": "stream", "text": "row 0 is <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>\nrow 1 is <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>\nrow 2 is <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>\nrow 3 is <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### As row is a cell object, we can apply the method find_all to it and extract table cells in the object cells using the tag td, this is all the children with the name td. The result is a list, each element corresponds to a cell and is a Tag object, we can iterate through this list as well. We can extract the content using the string attribute."}, {"metadata": {}, "cell_type": "code", "source": "for i,row in enumerate(table_rows):\n    print(\"row\",i)\n    cells=row.find_all('td')\n    for j,cell in enumerate(cells):\n        print('colunm',j,\"cell\",cell)", "execution_count": 32, "outputs": [{"output_type": "stream", "text": "row 0\ncolunm 0 cell <td id=\"flight\">Flight No</td>\ncolunm 1 cell <td>Launch site</td>\ncolunm 2 cell <td>Payload mass</td>\nrow 1\ncolunm 0 cell <td>1</td>\ncolunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td>\ncolunm 2 cell <td>300 kg</td>\nrow 2\ncolunm 0 cell <td>2</td>\ncolunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\ncolunm 2 cell <td>94 kg</td>\nrow 3\ncolunm 0 cell <td>3</td>\ncolunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td>\ncolunm 2 cell <td>80 kg</td>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Since we used a list we can match against any item in that list.\nlist_input=table_bs .find_all(name=[\"tr\", \"td\"])\nlist_input", "execution_count": 33, "outputs": [{"output_type": "execute_result", "execution_count": 33, "data": {"text/plain": "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n <td id=\"flight\">Flight No</td>,\n <td>Launch site</td>,\n <td>Payload mass</td>,\n <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>,\n <td>1</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td>,\n <td>300 kg</td>,\n <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n <td>2</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n <td>94 kg</td>,\n <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>,\n <td>3</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td>,\n <td>80 kg</td>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### If the argument is not recognized it will be turned into a filter on the tag\u2019s attributes. For example the id argument, Beautiful Soup will filter against each tag\u2019s id attribute. For example, the first td elements have a value of id of flight, therefore we can filter based on that id value"}, {"metadata": {}, "cell_type": "code", "source": "table_bs.find_all(id=\"flight\")", "execution_count": 34, "outputs": [{"output_type": "execute_result", "execution_count": 34, "data": {"text/plain": "[<td id=\"flight\">Flight No</td>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Find all the elements that have links to the Florida Wikipedia page:\nlist_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\nlist_input", "execution_count": 35, "outputs": [{"output_type": "execute_result", "execution_count": 35, "data": {"text/plain": "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a>,\n <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#If we set the  href attribute to True, regardless of what the value is, the code finds all tags with href value\ntable_bs.find_all(href=True)", "execution_count": 36, "outputs": [{"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a>,\n <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#find all the elements without href value\ntable_bs.find_all(href=False)", "execution_count": 37, "outputs": [{"output_type": "execute_result", "execution_count": 37, "data": {"text/plain": "[<table><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr></table>,\n <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n <td id=\"flight\">Flight No</td>,\n <td>Launch site</td>,\n <td>Payload mass</td>,\n <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>,\n <td>1</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td>,\n <a></a>,\n <td>300 kg</td>,\n <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n <td>2</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n <td>94 kg</td>,\n <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>,\n <td>3</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td>,\n <a> </a>,\n <td>80 kg</td>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#find the element with the id attribute content set to \"boldest\"\nsoup.find_all(id=\"boldest\")", "execution_count": 38, "outputs": [{"output_type": "execute_result", "execution_count": 38, "data": {"text/plain": "[<b id=\"boldest\">Lebron James</b>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#search for strings instead of tags, where we find all the elments with Florida\ntable_bs.find_all(string=\"Florida\")", "execution_count": 39, "outputs": [{"output_type": "execute_result", "execution_count": 39, "data": {"text/plain": "['Florida', 'Florida']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#We store the HTML as a Python string and assign two_tables:\n%%html\n<h3>Rocket Launch </h3>\n\n<p>\n<table class='rocket'>\n  <tr>\n    <td>Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n  </tr>\n  <tr>\n    <td>1</td>\n    <td>Florida</td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td>Texas</td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td>Florida </td>\n    <td>80 kg</td>\n  </tr>\n</table>\n</p>\n<p>\n\n<h3>Pizza Party  </h3>\n  \n    \n<table class='pizza'>\n  <tr>\n    <td>Pizza Place</td>\n    <td>Orders</td> \n    <td>Slices </td>\n   </tr>\n  <tr>\n    <td>Domino's Pizza</td>\n    <td>10</td>\n    <td>100</td>\n  </tr>\n  <tr>\n    <td>Little Caesars</td>\n    <td>12</td>\n    <td >144 </td>\n  </tr>\n  <tr>\n    <td>Papa John's </td>\n    <td>15 </td>\n    <td>165</td>\n  </tr>\n\n", "execution_count": 40, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<h3>Rocket Launch </h3>\n\n<p>\n<table class='rocket'>\n  <tr>\n    <td>Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n  </tr>\n  <tr>\n    <td>1</td>\n    <td>Florida</td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td>Texas</td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td>Florida </td>\n    <td>80 kg</td>\n  </tr>\n</table>\n</p>\n<p>\n\n<h3>Pizza Party  </h3>\n  \n    \n<table class='pizza'>\n  <tr>\n    <td>Pizza Place</td>\n    <td>Orders</td> \n    <td>Slices </td>\n   </tr>\n  <tr>\n    <td>Domino's Pizza</td>\n    <td>10</td>\n    <td>100</td>\n  </tr>\n  <tr>\n    <td>Little Caesars</td>\n    <td>12</td>\n    <td >144 </td>\n  </tr>\n  <tr>\n    <td>Papa John's </td>\n    <td>15 </td>\n    <td>165</td>\n  </tr>\n\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "two_tables=\"<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>\"", "execution_count": 41, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "two_tables_bs= BeautifulSoup(two_tables, 'html.parser')", "execution_count": 42, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Find the first table using the tag name table\ntwo_tables_bs.find(\"table\")", "execution_count": 43, "outputs": [{"output_type": "execute_result", "execution_count": 43, "data": {"text/plain": "<table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Filter on the class attribute to find the second table, but because class is a keyword in Python, we add an underscore.\ntwo_tables_bs.find(\"table\",class_='pizza')", "execution_count": 44, "outputs": [{"output_type": "execute_result", "execution_count": 44, "data": {"text/plain": "<table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Download the contents of the web page:"}, {"metadata": {}, "cell_type": "code", "source": "url = \"http://www.ibm.com\"", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Download the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text ", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create a BeautifulSoup object using the BeautifulSoup constructor\nsoup = BeautifulSoup(data,\"html.parser\")  # create a soup object using the variable 'data'", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Scrape all links\nfor link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n\n    print(link.get('href'))", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "#main-content\nhttp://www.ibm.com\nhttps://newsroom.ibm.com/Update-on-our-actions-War-in-Ukraine?lnk=ushpv18nf1\nhttp://ibm.com/lets-create?lnk=ushpv18l2\n#ibm-tech-section\nhttps://www.ibm.com/consulting/?lnk=ushpv18intro2\n#research\nhttps://www.ibm.com/thought-leadership/innovation-explanations/pin-yu-chen?lnk=ushpv18r1\nhttps://www.ibm.com/thought-leadership/innovation-explanations/pin-yu-chen?lnk=ushpv18r1\nhttps://research.ibm.com/blog/what-is-accelerated-discovery?lnk=ushpv18r2\nhttps://research.ibm.com/blog/smell-unlocks-conscious-thought-mystery?lnk=ushpv18r3\nhttps://research.ibm.com/blog/ml-for-enzyme-powered-green-chemistry?lnk=ushpv18r4\nhttps://www.ibm.com/cloud/satellite?lnk=ushpv18f1\nhttps://www.ibm.com/employment/women/?lnk=ushpv18f2\nhttps://www.ibm.com/security/data-breach/threat-intelligence/?lnk=ushpv18f3\nhttps://www.ibm.com/cloud/watson-discovery?lnk=ushpv18f4\nhttps://www.ibm.com/case-studies/search?lnk=ushpv18mAll\nhttps://www.ibm.com/case-studies/wichita-state-university/?lnk=ushpv18m1\nhttps://www.ibm.com/case-studies/hera-spa/?lnk=ushpv18m2\nhttps://www.ibm.com/case-studies/audi-uk/?lnk=ushpv18m3\nhttps://www.ibm.com/products?types[0]=trial&lnk=STW_US_MPDISC_BNR_BTN&lnk2=THP&lnk3=ushpv18tAll\nhttps://www.ibm.com/products/offers-and-discounts?link=ushpv18t5&lnk2=trial_mktpl_MPDISC\nhttps://www.ibm.com/cloud/openshift?lnk=ushpv18t1&lnk2=trial_RedHatOpenShift&psrc=none&pexp=def\nhttps://www.ibm.com/products/unified-endpoint-management?lnk=ushpv18t2&lnk2=trial_MaaS360Wat&psrc=none&pexp=def\nhttps://www.ibm.com/cloud/watson-studio?lnk=ushpv18t3&lnk2=trial_WatStudio&psrc=none&pexp=def\nhttps://www.ibm.com/search?lnk=ushpv18srch&locale=en-us&q=\nhttps://www.ibm.com/products?lnk=ushpv18p1&lnk2=trial_mktpl&psrc=none&pexp=def\nhttps://www.ibm.com/cloud/hybrid?lnk=ushpv18pt14\nhttps://www.ibm.com/watson?lnk=ushpv18pt17\nhttps://www.ibm.com/it-infrastructure?lnk=ushpv18pt19\nhttps://www.ibm.com/blockchain?lnk=ushpv18pt4\nhttps://www.ibm.com/security/products?lnk=ushpv18pt9\nhttps://www.ibm.com/analytics/products?lnk=ushpv18pt1\nhttps://www.ibm.com/cloud/automation?lnk=ushpv18ct21\nhttps://www.ibm.com/quantum-computing?lnk=ushpv18pt16\nhttps://www.ibm.com/mysupport/s/?language=en_US&lnk=ushpv18ct11\nhttps://www.ibm.com/training/?lnk=ushpv18ct15\nhttps://community.ibm.com/community/user/home/?lnk=ushpv18ct20\nhttps://developer.ibm.com/?lnk=ushpv18ct9\nhttps://www.ibm.com/garage?lnk=ushpv18pt18\nhttps://www.ibm.com/docs/en?lnk=ushpv18ct14\nhttps://www.redbooks.ibm.com/?lnk=ushpv18ct10\nhttps://www-03.ibm.com/employment/technicaltalent/developer/?lnk=ushpv18ct2\nhttps://www.ibm.com/\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Scrape all images Tags"}, {"metadata": {}, "cell_type": "code", "source": "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n    print(link)\n    print(link.get('src'))", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "<img alt=\" \" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/98/c1/20220307-R1-pin-yu-chen-interview-26471-1600x900.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/98/c1/20220307-R1-pin-yu-chen-interview-26471-1600x900.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/2d/7f/reserach-th-accelerated-discovery-800x450.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/2d/7f/reserach-th-accelerated-discovery-800x450.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/91/ec/20220307-R2-computing-smell-26461-800x450.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/91/ec/20220307-R2-computing-smell-26461-800x450.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\" https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/69/db/20220228-r-green-chemistry-enzymes-26440-800x450.jpg\"/>\n https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/69/db/20220228-r-green-chemistry-enzymes-26440-800x450.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/f1/18/20210308-f-cloud-sattelite-25768.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/f1/18/20210308-f-cloud-sattelite-25768.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\" https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/bc/54/20220307-f-ibm-women-careers-444x320-26467.jpg \"/>\n https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/bc/54/20220307-f-ibm-women-careers-444x320-26467.jpg \n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/15/b5/20220228-f-x-force-intel-report-26413-444x320-26413.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/15/b5/20220228-f-x-force-intel-report-26413-444x320-26413.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/6a/96/20210208-watson-discovery-search-enterprise-data-444x320.gif\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/6a/96/20210208-watson-discovery-search-enterprise-data-444x320.gif\n<img alt=\" \" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/f0/e3/20220307-WSU-26463-1600x900.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/f0/e3/20220307-WSU-26463-1600x900.jpg\n<img alt=\" \" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/26/cc/creativity-story-hera-spa.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/26/cc/creativity-story-hera-spa.jpg\n<img alt=\" \" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/4c/98/creative-story-audi-garage-app.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/4c/98/creative-story-audi-garage-app.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/ea/62/Redhat-Openshift-on-Cloud-trial-800x450.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/ea/62/Redhat-Openshift-on-Cloud-trial-800x450.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/ed/21/MaaS360-with-Watson-trial-800x450.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/ed/21/MaaS360-with-Watson-trial-800x450.jpg\n<img alt=\" \" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/6a/27/Watson-Studio-trial-800x450.jpg\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/6a/27/Watson-Studio-trial-800x450.jpg\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Scrape data from HTML tables"}, {"metadata": {}, "cell_type": "code", "source": "#The below url contains an html table with data about colors and color codes. Note: Always open the webpage to view how its contents are organized\nurl = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# get the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "soup = BeautifulSoup(data,\"html.parser\")", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#find a html table in the web page\ntable = soup.find('table') # in html table is represented by the tag <table>", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Get all rows from the table\nfor row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n    # Get all columns in each row.\n    cols = row.find_all('td') # in html a column is represented by the tag <td>\n    color_name = cols[2].string # store the value in column 3 as color_name\n    color_code = cols[3].string # store the value in column 4 as color_code\n    print(\"{}--->{}\".format(color_name,color_code))", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Color Name--->None\nlightsalmon--->#FFA07A\nsalmon--->#FA8072\ndarksalmon--->#E9967A\nlightcoral--->#F08080\ncoral--->#FF7F50\ntomato--->#FF6347\norangered--->#FF4500\ngold--->#FFD700\norange--->#FFA500\ndarkorange--->#FF8C00\nlightyellow--->#FFFFE0\nlemonchiffon--->#FFFACD\npapayawhip--->#FFEFD5\nmoccasin--->#FFE4B5\npeachpuff--->#FFDAB9\npalegoldenrod--->#EEE8AA\nkhaki--->#F0E68C\ndarkkhaki--->#BDB76B\nyellow--->#FFFF00\nlawngreen--->#7CFC00\nchartreuse--->#7FFF00\nlimegreen--->#32CD32\nlime--->#00FF00\nforestgreen--->#228B22\ngreen--->#008000\npowderblue--->#B0E0E6\nlightblue--->#ADD8E6\nlightskyblue--->#87CEFA\nskyblue--->#87CEEB\ndeepskyblue--->#00BFFF\nlightsteelblue--->#B0C4DE\ndodgerblue--->#1E90FF\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Scrape data from HTML tables into a DataFrame using BeautifulSoup and Pandas"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#The below url contains html tables with data about world population.\nurl = \"https://en.wikipedia.org/wiki/World_population\"", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# get the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "soup = BeautifulSoup(data,\"html.parser\")", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#find all html tables in the web page\ntables = soup.find_all('table') # in html table is represented by the tag <table>", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# we can see how many tables were found by checking the length of the tables list\nlen(tables)", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "26"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Look for '10 most densly populated countries' in the table, we can look through the tables list and find the right one we are look for based on the data in each table or we can search for the table name if it is in the table but this option might not always work"}, {"metadata": {}, "cell_type": "code", "source": "for index,table in enumerate(tables):\n    if (\"10 most densely populated countries\" in str(table)):\n        table_index = index\nprint(table_index)", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "5\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Locate the table name of the table, 10 most densly populated countries\nprint(tables[table_index].prettify())", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "<table class=\"wikitable sortable\" style=\"text-align:right\">\n <caption>\n  10 most densely populated countries\n  <small>\n   (with population above 5 million)\n  </small>\n </caption>\n <tbody>\n  <tr>\n   <th>\n    Rank\n   </th>\n   <th>\n    Country\n   </th>\n   <th>\n    Population\n   </th>\n   <th>\n    Area\n    <br/>\n    <small>\n     (km\n     <sup>\n      2\n     </sup>\n     )\n    </small>\n   </th>\n   <th>\n    Density\n    <br/>\n    <small>\n     (pop/km\n     <sup>\n      2\n     </sup>\n     )\n    </small>\n   </th>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/23px-Flag_of_Singapore.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/35px-Flag_of_Singapore.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/45px-Flag_of_Singapore.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/Singapore\" title=\"Singapore\">\n     Singapore\n    </a>\n   </td>\n   <td>\n    5,704,000\n   </td>\n   <td>\n    710\n   </td>\n   <td>\n    8,033\n   </td>\n  </tr>\n  <tr>\n   <td>\n    2\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1000\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/23px-Flag_of_Bangladesh.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/35px-Flag_of_Bangladesh.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/46px-Flag_of_Bangladesh.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/Bangladesh\" title=\"Bangladesh\">\n     Bangladesh\n    </a>\n   </td>\n   <td>\n    172,370,000\n   </td>\n   <td>\n    143,998\n   </td>\n   <td>\n    1,197\n   </td>\n  </tr>\n  <tr>\n   <td>\n    3\n   </td>\n   <td align=\"left\">\n    <p>\n     <span class=\"flagicon\">\n      <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1200\" decoding=\"async\" height=\"12\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/23px-Flag_of_Palestine.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/35px-Flag_of_Palestine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/46px-Flag_of_Palestine.svg.png 2x\" width=\"23\"/>\n     </span>\n     <a href=\"/wiki/State_of_Palestine\" title=\"State of Palestine\">\n      Palestine\n     </a>\n    </p>\n   </td>\n   <td>\n    5,266,785\n   </td>\n   <td>\n    6,020\n   </td>\n   <td>\n    847\n   </td>\n  </tr>\n  <tr>\n   <td>\n    4\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/23px-Flag_of_Lebanon.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/35px-Flag_of_Lebanon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/45px-Flag_of_Lebanon.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/Lebanon\" title=\"Lebanon\">\n     Lebanon\n    </a>\n   </td>\n   <td>\n    6,856,000\n   </td>\n   <td>\n    10,452\n   </td>\n   <td>\n    656\n   </td>\n  </tr>\n  <tr>\n   <td>\n    5\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/23px-Flag_of_the_Republic_of_China.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/35px-Flag_of_the_Republic_of_China.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/45px-Flag_of_the_Republic_of_China.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/Taiwan\" title=\"Taiwan\">\n     Taiwan\n    </a>\n   </td>\n   <td>\n    23,604,000\n   </td>\n   <td>\n    36,193\n   </td>\n   <td>\n    652\n   </td>\n  </tr>\n  <tr>\n   <td>\n    6\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/23px-Flag_of_South_Korea.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/35px-Flag_of_South_Korea.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/45px-Flag_of_South_Korea.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/South_Korea\" title=\"South Korea\">\n     South Korea\n    </a>\n   </td>\n   <td>\n    51,781,000\n   </td>\n   <td>\n    99,538\n   </td>\n   <td>\n    520\n   </td>\n  </tr>\n  <tr>\n   <td>\n    7\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"720\" data-file-width=\"1080\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/23px-Flag_of_Rwanda.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/35px-Flag_of_Rwanda.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/45px-Flag_of_Rwanda.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/Rwanda\" title=\"Rwanda\">\n     Rwanda\n    </a>\n   </td>\n   <td>\n    12,374,000\n   </td>\n   <td>\n    26,338\n   </td>\n   <td>\n    470\n   </td>\n  </tr>\n  <tr>\n   <td>\n    8\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1000\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/56/Flag_of_Haiti.svg/23px-Flag_of_Haiti.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/56/Flag_of_Haiti.svg/35px-Flag_of_Haiti.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/56/Flag_of_Haiti.svg/46px-Flag_of_Haiti.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/Haiti\" title=\"Haiti\">\n     Haiti\n    </a>\n   </td>\n   <td>\n    11,578,000\n   </td>\n   <td>\n    27,065\n   </td>\n   <td>\n    428\n   </td>\n  </tr>\n  <tr>\n   <td>\n    9\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/23px-Flag_of_the_Netherlands.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/35px-Flag_of_the_Netherlands.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/45px-Flag_of_the_Netherlands.svg.png 2x\" width=\"23\"/>\n    </span>\n    <a href=\"/wiki/Netherlands\" title=\"Netherlands\">\n     Netherlands\n    </a>\n   </td>\n   <td>\n    17,700,000\n   </td>\n   <td>\n    41,526\n   </td>\n   <td>\n    426\n   </td>\n  </tr>\n  <tr>\n   <td>\n    10\n   </td>\n   <td align=\"left\">\n    <span class=\"flagicon\">\n     <img alt=\"\" class=\"thumbborder\" data-file-height=\"800\" data-file-width=\"1100\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/21px-Flag_of_Israel.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/32px-Flag_of_Israel.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/41px-Flag_of_Israel.svg.png 2x\" width=\"21\"/>\n    </span>\n    <a href=\"/wiki/Israel\" title=\"Israel\">\n     Israel\n    </a>\n   </td>\n   <td>\n    9,490,000\n   </td>\n   <td>\n    22,072\n   </td>\n   <td>\n    430\n   </td>\n  </tr>\n </tbody>\n</table>\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "population_data = pd.DataFrame(columns=[\"Rank\", \"Country\", \"Population\", \"Area\", \"Density\"])\n\nfor row in tables[table_index].tbody.find_all(\"tr\"):\n    col = row.find_all(\"td\")\n    if (col != []):\n        rank = col[0].text\n        country = col[1].text\n        population = col[2].text.strip()\n        area = col[3].text.strip()\n        density = col[4].text.strip()\n        population_data = population_data.append({\"Rank\":rank, \"Country\":country, \"Population\":population, \"Area\":area, \"Density\":density}, ignore_index=True)\n\npopulation_data", "execution_count": 22, "outputs": [{"output_type": "execute_result", "execution_count": 22, "data": {"text/plain": "  Rank           Country   Population     Area Density\n0    1        \u00a0Singapore    5,704,000      710   8,033\n1    2       \u00a0Bangladesh  172,370,000  143,998   1,197\n2    3  \\n\u00a0Palestine\\n\\n    5,266,785    6,020     847\n3    4          \u00a0Lebanon    6,856,000   10,452     656\n4    5           \u00a0Taiwan   23,604,000   36,193     652\n5    6      \u00a0South Korea   51,781,000   99,538     520\n6    7           \u00a0Rwanda   12,374,000   26,338     470\n7    8            \u00a0Haiti   11,578,000   27,065     428\n8    9      \u00a0Netherlands   17,700,000   41,526     426\n9   10           \u00a0Israel    9,490,000   22,072     430", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country</th>\n      <th>Population</th>\n      <th>Area</th>\n      <th>Density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Singapore</td>\n      <td>5,704,000</td>\n      <td>710</td>\n      <td>8,033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bangladesh</td>\n      <td>172,370,000</td>\n      <td>143,998</td>\n      <td>1,197</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>\\n\u00a0Palestine\\n\\n</td>\n      <td>5,266,785</td>\n      <td>6,020</td>\n      <td>847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lebanon</td>\n      <td>6,856,000</td>\n      <td>10,452</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Taiwan</td>\n      <td>23,604,000</td>\n      <td>36,193</td>\n      <td>652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>South Korea</td>\n      <td>51,781,000</td>\n      <td>99,538</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Rwanda</td>\n      <td>12,374,000</td>\n      <td>26,338</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Haiti</td>\n      <td>11,578,000</td>\n      <td>27,065</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Netherlands</td>\n      <td>17,700,000</td>\n      <td>41,526</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Israel</td>\n      <td>9,490,000</td>\n      <td>22,072</td>\n      <td>430</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Scrape data from HTML tables into a DataFrame using BeautifulSoup and read_html\n\nUsing the same url, data, soup, and tables object as in the last section we can use the read_html function to create a DataFrame.\n\nRemember the table we need is located in tables[table_index]\n\nWe can now use the pandas function read_html and give it the string version of the table as well as the flavor which is the parsing engine bs4."}, {"metadata": {}, "cell_type": "code", "source": "#The function read_html always returns a list of DataFrames so we must pick the one we want out of the list.\npd.read_html(str(tables[5]), flavor='bs4')", "execution_count": 23, "outputs": [{"output_type": "execute_result", "execution_count": 23, "data": {"text/plain": "[   Rank      Country  Population  Area(km2)  Density(pop/km2)\n 0     1    Singapore     5704000        710              8033\n 1     2   Bangladesh   172370000     143998              1197\n 2     3    Palestine     5266785       6020               847\n 3     4      Lebanon     6856000      10452               656\n 4     5       Taiwan    23604000      36193               652\n 5     6  South Korea    51781000      99538               520\n 6     7       Rwanda    12374000      26338               470\n 7     8        Haiti    11578000      27065               428\n 8     9  Netherlands    17700000      41526               426\n 9    10       Israel     9490000      22072               430]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "population_data_read_html = pd.read_html(str(tables[5]), flavor='bs4')[0]\n\npopulation_data_read_html", "execution_count": 24, "outputs": [{"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n0     1    Singapore     5704000        710              8033\n1     2   Bangladesh   172370000     143998              1197\n2     3    Palestine     5266785       6020               847\n3     4      Lebanon     6856000      10452               656\n4     5       Taiwan    23604000      36193               652\n5     6  South Korea    51781000      99538               520\n6     7       Rwanda    12374000      26338               470\n7     8        Haiti    11578000      27065               428\n8     9  Netherlands    17700000      41526               426\n9    10       Israel     9490000      22072               430", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country</th>\n      <th>Population</th>\n      <th>Area(km2)</th>\n      <th>Density(pop/km2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Singapore</td>\n      <td>5704000</td>\n      <td>710</td>\n      <td>8033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bangladesh</td>\n      <td>172370000</td>\n      <td>143998</td>\n      <td>1197</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Palestine</td>\n      <td>5266785</td>\n      <td>6020</td>\n      <td>847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lebanon</td>\n      <td>6856000</td>\n      <td>10452</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Taiwan</td>\n      <td>23604000</td>\n      <td>36193</td>\n      <td>652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>South Korea</td>\n      <td>51781000</td>\n      <td>99538</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Rwanda</td>\n      <td>12374000</td>\n      <td>26338</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Haiti</td>\n      <td>11578000</td>\n      <td>27065</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Netherlands</td>\n      <td>17700000</td>\n      <td>41526</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Israel</td>\n      <td>9490000</td>\n      <td>22072</td>\n      <td>430</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Scrape data from HTML tables into a DataFrame using read_html"}, {"metadata": {}, "cell_type": "code", "source": "# read_html function to directly get DataFrames from a url.\ndataframe_list = pd.read_html(url, flavor='bs4')", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Number of dataframes\nlen(dataframe_list)", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "26"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Pick the DataFrame we need out of the list.\ndataframe_list[5]", "execution_count": 27, "outputs": [{"output_type": "execute_result", "execution_count": 27, "data": {"text/plain": "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n0     1    Singapore     5704000        710              8033\n1     2   Bangladesh   172370000     143998              1197\n2     3    Palestine     5266785       6020               847\n3     4      Lebanon     6856000      10452               656\n4     5       Taiwan    23604000      36193               652\n5     6  South Korea    51781000      99538               520\n6     7       Rwanda    12374000      26338               470\n7     8        Haiti    11578000      27065               428\n8     9  Netherlands    17700000      41526               426\n9    10       Israel     9490000      22072               430", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country</th>\n      <th>Population</th>\n      <th>Area(km2)</th>\n      <th>Density(pop/km2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Singapore</td>\n      <td>5704000</td>\n      <td>710</td>\n      <td>8033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bangladesh</td>\n      <td>172370000</td>\n      <td>143998</td>\n      <td>1197</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Palestine</td>\n      <td>5266785</td>\n      <td>6020</td>\n      <td>847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lebanon</td>\n      <td>6856000</td>\n      <td>10452</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Taiwan</td>\n      <td>23604000</td>\n      <td>36193</td>\n      <td>652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>South Korea</td>\n      <td>51781000</td>\n      <td>99538</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Rwanda</td>\n      <td>12374000</td>\n      <td>26338</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Haiti</td>\n      <td>11578000</td>\n      <td>27065</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Netherlands</td>\n      <td>17700000</td>\n      <td>41526</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Israel</td>\n      <td>9490000</td>\n      <td>22072</td>\n      <td>430</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# 'match'- parameter to select the specific table we want. If the table contains a string matching the text it will be read.\npd.read_html(url, match=\"10 most densely populated countries\", flavor='bs4')[0]", "execution_count": 28, "outputs": [{"output_type": "execute_result", "execution_count": 28, "data": {"text/plain": "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n0     1    Singapore     5704000        710              8033\n1     2   Bangladesh   172370000     143998              1197\n2     3    Palestine     5266785       6020               847\n3     4      Lebanon     6856000      10452               656\n4     5       Taiwan    23604000      36193               652\n5     6  South Korea    51781000      99538               520\n6     7       Rwanda    12374000      26338               470\n7     8        Haiti    11578000      27065               428\n8     9  Netherlands    17700000      41526               426\n9    10       Israel     9490000      22072               430", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country</th>\n      <th>Population</th>\n      <th>Area(km2)</th>\n      <th>Density(pop/km2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Singapore</td>\n      <td>5704000</td>\n      <td>710</td>\n      <td>8033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bangladesh</td>\n      <td>172370000</td>\n      <td>143998</td>\n      <td>1197</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Palestine</td>\n      <td>5266785</td>\n      <td>6020</td>\n      <td>847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lebanon</td>\n      <td>6856000</td>\n      <td>10452</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Taiwan</td>\n      <td>23604000</td>\n      <td>36193</td>\n      <td>652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>South Korea</td>\n      <td>51781000</td>\n      <td>99538</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Rwanda</td>\n      <td>12374000</td>\n      <td>26338</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Haiti</td>\n      <td>11578000</td>\n      <td>27065</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Netherlands</td>\n      <td>17700000</td>\n      <td>41526</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Israel</td>\n      <td>9490000</td>\n      <td>22072</td>\n      <td>430</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}